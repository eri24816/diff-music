{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PianorollDataset initialized with 20078 segments from 2570 songs\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from music_data_analysis import Pianoroll\n",
    "import torch\n",
    "from torch import Tensor\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from diff_music.data.dataset import PianorollDataset\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from diff_music.models.midilike_transformer import MidiLikeTransformer\n",
    "\n",
    "# ds_path = Path(r'W:\\music\\music-data-analysis\\data')\n",
    "ds_path = Path('W:/piano-ai/pop80k_k')\n",
    "ds = PianorollDataset(ds_path, frames_per_beat=8, length=32*4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from diff_music.models.midilike_transformer import collate_fn\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class TrainingParams:\n",
    "    batch_size: int\n",
    "    learning_rate: float\n",
    "    num_epochs: int\n",
    "    num_workers: int\n",
    "    generate_steps: int\n",
    "\n",
    "training_params = TrainingParams(\n",
    "    batch_size=32,\n",
    "    learning_rate=1e-4,\n",
    "    num_epochs=100,\n",
    "    num_workers=10,\n",
    "    generate_steps=200,\n",
    ")\n",
    "\n",
    "dataloader = DataLoader(ds, batch_size=training_params.batch_size, shuffle=True, drop_last=True, collate_fn=collate_fn, num_workers=training_params.num_workers, persistent_workers=training_params.num_workers > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "device = torch.device('cuda')\n",
    "\n",
    "\n",
    "model_params = MidiLikeTransformer.Params(\n",
    "    hidden_dim=512,\n",
    "    num_layers=4,\n",
    "    pitch_range=[21, 109],\n",
    "    max_len=1024\n",
    ")\n",
    "model = MidiLikeTransformer(model_params)\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "optim = torch.optim.Adam(model.parameters(), lr=training_params.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33meri24816\u001b[0m (\u001b[33mtanchihpin0517-team\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>w:\\piano-ai\\diff_music\\wandb\\run-20250316_181047-20250316_181047</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/tanchihpin0517-team/vqpiano/runs/20250316_181047' target=\"_blank\">20250316_181047</a></strong> to <a href='https://wandb.ai/tanchihpin0517-team/vqpiano' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/tanchihpin0517-team/vqpiano' target=\"_blank\">https://wandb.ai/tanchihpin0517-team/vqpiano</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/tanchihpin0517-team/vqpiano/runs/20250316_181047' target=\"_blank\">https://wandb.ai/tanchihpin0517-team/vqpiano/runs/20250316_181047</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import wandb\n",
    "run = wandb.init(\n",
    "    # Set the project where this run will be logged\n",
    "    project=\"vqpiano\",\n",
    "    group=\"midilike-scratch\",\n",
    "    id=datetime.now().strftime(\"%Y%m%d_%H%M%S\"),\n",
    "    # Track hyperparameters and run metadata\n",
    "    config={\n",
    "        \"ds_path\": ds_path,\n",
    "        \"training\": training_params,\n",
    "        \"model\": model_params,\n",
    "    },\n",
    ")\n",
    "step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 58/128 [00:06<00:08,  8.33it/s] loss=1.5, pitch_acc=0.00117, pitch_loss=1.01, token_type_acc=0.788, token_type_loss=0.492]\n",
      "100%|██████████| 128/128 [00:00<00:00, 150.51it/s].96it/s, loss=1.05, pitch_acc=0.0578, pitch_loss=0.725, token_type_acc=0.852, token_type_loss=0.329] \n",
      "100%|██████████| 128/128 [00:01<00:00, 76.33it/s]6.22it/s, loss=0.854, pitch_acc=0.0716, pitch_loss=0.582, token_type_acc=0.874, token_type_loss=0.272]\n",
      "100%|██████████| 128/128 [00:01<00:00, 118.81it/s].98it/s, loss=0.856, pitch_acc=0.0674, pitch_loss=0.576, token_type_acc=0.878, token_type_loss=0.28] \n",
      "Epoch 0: 100%|██████████| 627/627 [02:20<00:00,  4.46it/s, loss=0.961, pitch_acc=0.0819, pitch_loss=0.657, token_type_acc=0.862, token_type_loss=0.304]\n",
      "100%|██████████| 128/128 [00:00<00:00, 141.18it/s].62it/s, loss=0.756, pitch_acc=0.0728, pitch_loss=0.514, token_type_acc=0.897, token_type_loss=0.242]\n",
      "100%|██████████| 128/128 [00:01<00:00, 95.10it/s]4.77it/s, loss=0.908, pitch_acc=0.0819, pitch_loss=0.612, token_type_acc=0.872, token_type_loss=0.296]\n",
      "100%|██████████| 128/128 [00:00<00:00, 170.93it/s].47it/s, loss=0.745, pitch_acc=0.0757, pitch_loss=0.512, token_type_acc=0.902, token_type_loss=0.233]\n",
      "Epoch 1: 100%|██████████| 627/627 [02:16<00:00,  4.59it/s, loss=0.735, pitch_acc=0.0676, pitch_loss=0.505, token_type_acc=0.898, token_type_loss=0.23] \n",
      "100%|██████████| 128/128 [00:01<00:00, 97.87it/s] .00it/s, loss=0.823, pitch_acc=0.0947, pitch_loss=0.551, token_type_acc=0.883, token_type_loss=0.272]\n",
      "100%|██████████| 128/128 [00:01<00:00, 109.50it/s].71it/s, loss=0.926, pitch_acc=0.0903, pitch_loss=0.619, token_type_acc=0.864, token_type_loss=0.307]\n",
      "Epoch 2:  84%|████████▍ | 528/627 [01:55<00:21,  4.56it/s, loss=0.79, pitch_acc=0.103, pitch_loss=0.534, token_type_acc=0.892, token_type_loss=0.256]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(training_params.num_epochs):\n\u001b[32m      5\u001b[39m     pbar = tqdm(dataloader, desc=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpbar\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\miniconda3\\envs\\13\\Lib\\site-packages\\tqdm\\std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[32m   1184\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\miniconda3\\envs\\13\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:708\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    705\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    706\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    707\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m708\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    709\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    710\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    711\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    712\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    713\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    714\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\miniconda3\\envs\\13\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1458\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1455\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._process_data(data)\n\u001b[32m   1457\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._tasks_outstanding > \u001b[32m0\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1458\u001b[39m idx, data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1459\u001b[39m \u001b[38;5;28mself\u001b[39m._tasks_outstanding -= \u001b[32m1\u001b[39m\n\u001b[32m   1460\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable:\n\u001b[32m   1461\u001b[39m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\miniconda3\\envs\\13\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1420\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._get_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1416\u001b[39m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[32m   1417\u001b[39m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[32m   1418\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1419\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1420\u001b[39m         success, data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1421\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[32m   1422\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\miniconda3\\envs\\13\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1251\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._try_get_data\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m   1238\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout=_utils.MP_STATUS_CHECK_INTERVAL):\n\u001b[32m   1239\u001b[39m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[32m   1240\u001b[39m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1248\u001b[39m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[32m   1249\u001b[39m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[32m   1250\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1251\u001b[39m         data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data_queue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1252\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[32m   1253\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1254\u001b[39m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[32m   1255\u001b[39m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[32m   1256\u001b[39m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\miniconda3\\envs\\13\\Lib\\multiprocessing\\queues.py:111\u001b[39m, in \u001b[36mQueue.get\u001b[39m\u001b[34m(self, block, timeout)\u001b[39m\n\u001b[32m    109\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[32m    110\u001b[39m     timeout = deadline - time.monotonic()\n\u001b[32m--> \u001b[39m\u001b[32m111\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    112\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[32m    113\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._poll():\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\miniconda3\\envs\\13\\Lib\\multiprocessing\\connection.py:257\u001b[39m, in \u001b[36m_ConnectionBase.poll\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    255\u001b[39m \u001b[38;5;28mself\u001b[39m._check_closed()\n\u001b[32m    256\u001b[39m \u001b[38;5;28mself\u001b[39m._check_readable()\n\u001b[32m--> \u001b[39m\u001b[32m257\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\miniconda3\\envs\\13\\Lib\\multiprocessing\\connection.py:346\u001b[39m, in \u001b[36mPipeConnection._poll\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._got_empty_message \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[32m    344\u001b[39m             _winapi.PeekNamedPipe(\u001b[38;5;28mself\u001b[39m._handle)[\u001b[32m0\u001b[39m] != \u001b[32m0\u001b[39m):\n\u001b[32m    345\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m346\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\miniconda3\\envs\\13\\Lib\\multiprocessing\\connection.py:1096\u001b[39m, in \u001b[36mwait\u001b[39m\u001b[34m(object_list, timeout)\u001b[39m\n\u001b[32m   1093\u001b[39m                 ready_objects.add(o)\n\u001b[32m   1094\u001b[39m                 timeout = \u001b[32m0\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1096\u001b[39m     ready_handles = \u001b[43m_exhaustive_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwaithandle_to_obj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1097\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m   1098\u001b[39m     \u001b[38;5;66;03m# request that overlapped reads stop\u001b[39;00m\n\u001b[32m   1099\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m ov \u001b[38;5;129;01min\u001b[39;00m ov_list:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\miniconda3\\envs\\13\\Lib\\multiprocessing\\connection.py:1028\u001b[39m, in \u001b[36m_exhaustive_wait\u001b[39m\u001b[34m(handles, timeout)\u001b[39m\n\u001b[32m   1026\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m L:\n\u001b[32m   1027\u001b[39m     short_L = L[:\u001b[32m60\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(L) > \u001b[32m60\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m L\n\u001b[32m-> \u001b[39m\u001b[32m1028\u001b[39m     res = \u001b[43m_winapi\u001b[49m\u001b[43m.\u001b[49m\u001b[43mWaitForMultipleObjects\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshort_L\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1029\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m res == WAIT_TIMEOUT:\n\u001b[32m   1030\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import torch_util.wandb\n",
    "\n",
    "for epoch in range(training_params.num_epochs):\n",
    "    pbar = tqdm(dataloader, desc=f\"Epoch {epoch}\")\n",
    "    for token, token_type, pos in pbar:\n",
    "        model.train()\n",
    "\n",
    "        token = token.to(device)\n",
    "        token_type = token_type.to(device)\n",
    "        pos = pos.to(device)\n",
    "\n",
    "        loss = model.calculate_loss(token, token_type, pos)\n",
    "        \n",
    "        optim.zero_grad()\n",
    "        loss.total_loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        pbar.set_postfix(loss=loss.total_loss.item(), pitch_loss=loss.pitch_loss.item(), token_type_loss=loss.token_type_loss.item(), pitch_acc=loss.pitch_acc, token_type_acc=loss.token_type_acc)\n",
    "        wandb.log({\n",
    "            \"loss\": loss.total_loss.item(),\n",
    "            \"pitch_loss\": loss.pitch_loss.item(),\n",
    "            \"token_type_loss\": loss.token_type_loss.item(),\n",
    "            \"pitch_acc\": loss.pitch_acc,\n",
    "            \"token_type_acc\": loss.token_type_acc,\n",
    "        }, step=step)\n",
    "\n",
    "        if (step % training_params.generate_steps == 0):\n",
    "            model.eval()\n",
    "            pr = model.sample_midi(128)\n",
    "            torch_util.wandb.log_midi_as_audio(pr.to_midi(), 'audio', step)\n",
    "            torch_util.wandb.log_image(pr.to_tensor().t().flip(0), 'pr', step)\n",
    "\n",
    "        \n",
    "        step += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 88])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr.to_tensor().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 140.88it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "78"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "pr = model.sample_midi(128)\n",
    "pr.to_midi('sample.mid')\n",
    "len(pr.notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  0],\n",
       "        [34, 47],\n",
       "        [51, 61],\n",
       "        [53, 63],\n",
       "        [58, 67],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [41, 50],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [46, 58],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [58, 69],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [41, 55],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [46, 65],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [58, 58],\n",
       "        [65, 75],\n",
       "        [69, 83],\n",
       "        [ 0,  0],\n",
       "        [63, 58],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [41, 53],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [46, 63],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [58, 53],\n",
       "        [65, 79],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [41, 53],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [46, 62],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [34, 49],\n",
       "        [51, 64],\n",
       "        [53, 68],\n",
       "        [58, 76],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [41, 56],\n",
       "        [57, 75],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [46, 66],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [55, 78],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [41, 61],\n",
       "        [53, 67],\n",
       "        [58, 74],\n",
       "        [60, 81],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [46, 62],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [57, 69],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [41, 50],\n",
       "        [53, 45],\n",
       "        [58, 65],\n",
       "        [62, 76],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [46, 62],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [60, 69],\n",
       "        [65, 85],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [41, 59],\n",
       "        [58, 75],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [46, 65],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [34, 54],\n",
       "        [51, 68],\n",
       "        [53, 72],\n",
       "        [58, 82],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [41, 59],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [46, 65],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [58, 74],\n",
       "        [ 0,  0],\n",
       "        [46, 33],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [41, 59],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [46, 64],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [58, 55],\n",
       "        [63, 68],\n",
       "        [65, 80],\n",
       "        [69, 87],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [41, 51],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [46, 62],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [58, 63],\n",
       "        [65, 81],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [41, 59],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [46, 62],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [51, 67],\n",
       "        [53, 69],\n",
       "        [58, 82],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [41, 57],\n",
       "        [53, 51],\n",
       "        [57, 79],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [46, 57],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [55, 78],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [41, 60],\n",
       "        [53, 73],\n",
       "        [58, 74],\n",
       "        [60, 83],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [46, 56],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [57, 73],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [41, 61],\n",
       "        [58, 70],\n",
       "        [62, 82],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [46, 65],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [60, 69],\n",
       "        [65, 85],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [58, 74],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0]], device='cuda:0')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  0,   0,   0,   0,   0,   1,   2,   3,   4,   4,   5,   6,   6,   7,\n",
       "          8,   8,   9,  10,  11,  12,  12,  13,  14,  14,  15,  16,  16,  16,\n",
       "         16,  17,  17,  18,  19,  20,  20,  21,  22,  22,  23,  24,  24,  24,\n",
       "         25,  26,  27,  28,  28,  29,  30,  30,  31,  32,  32,  32,  32,  32,\n",
       "         33,  34,  35,  36,  36,  36,  37,  38,  38,  39,  40,  40,  41,  42,\n",
       "         43,  44,  44,  44,  44,  44,  45,  46,  46,  47,  48,  48,  49,  50,\n",
       "         51,  52,  52,  52,  52,  52,  53,  54,  54,  55,  56,  56,  56,  57,\n",
       "         58,  59,  60,  60,  60,  61,  62,  62,  63,  64,  64,  64,  64,  64,\n",
       "         65,  66,  67,  68,  68,  69,  70,  70,  71,  72,  72,  73,  73,  74,\n",
       "         75,  76,  76,  77,  78,  78,  79,  80,  80,  80,  80,  80,  81,  82,\n",
       "         83,  84,  84,  85,  86,  86,  87,  88,  88,  88,  89,  90,  91,  92,\n",
       "         92,  93,  94,  94,  95,  96,  96,  96,  96,  97,  98,  99, 100, 100,\n",
       "        100, 100, 101, 102, 102, 103, 104, 104, 105, 106, 107, 108, 108, 108,\n",
       "        108, 108, 109, 110, 110, 111, 112, 112, 113, 114, 115, 116, 116, 116,\n",
       "        116, 117, 118, 118, 119, 120, 120, 120, 121, 122, 123, 124, 124,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0], device='cuda:0')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [0, 0],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [0, 0],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [0, 1]], device='cuda:0')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_type[:,:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 4.0581, -4.0700]],\n",
      "\n",
      "        [[ 4.0581, -4.0700]],\n",
      "\n",
      "        [[ 4.0581, -4.0700]],\n",
      "\n",
      "        [[ 4.0581, -4.0700]],\n",
      "\n",
      "        [[ 4.0581, -4.0700]],\n",
      "\n",
      "        [[ 4.0581, -4.0700]],\n",
      "\n",
      "        [[ 4.0581, -4.0700]],\n",
      "\n",
      "        [[ 4.0581, -4.0700]],\n",
      "\n",
      "        [[ 4.0581, -4.0700]],\n",
      "\n",
      "        [[ 4.0581, -4.0700]],\n",
      "\n",
      "        [[ 4.0581, -4.0700]],\n",
      "\n",
      "        [[ 4.0581, -4.0700]],\n",
      "\n",
      "        [[ 4.0581, -4.0700]],\n",
      "\n",
      "        [[ 4.0581, -4.0700]],\n",
      "\n",
      "        [[ 4.0581, -4.0700]],\n",
      "\n",
      "        [[ 4.0581, -4.0700]],\n",
      "\n",
      "        [[ 4.0581, -4.0700]],\n",
      "\n",
      "        [[ 4.0581, -4.0700]],\n",
      "\n",
      "        [[ 4.0581, -4.0700]],\n",
      "\n",
      "        [[ 4.0581, -4.0700]],\n",
      "\n",
      "        [[ 4.0581, -4.0700]],\n",
      "\n",
      "        [[ 4.0581, -4.0700]],\n",
      "\n",
      "        [[ 4.0581, -4.0700]],\n",
      "\n",
      "        [[ 4.0581, -4.0700]],\n",
      "\n",
      "        [[ 4.0581, -4.0700]],\n",
      "\n",
      "        [[ 4.0581, -4.0700]],\n",
      "\n",
      "        [[ 4.0581, -4.0700]],\n",
      "\n",
      "        [[ 4.0581, -4.0700]],\n",
      "\n",
      "        [[ 4.0581, -4.0700]],\n",
      "\n",
      "        [[ 4.0581, -4.0700]],\n",
      "\n",
      "        [[ 4.0581, -4.0700]],\n",
      "\n",
      "        [[ 4.0581, -4.0700]]], device='cuda:0', grad_fn=<SliceBackward0>) tensor([[1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "a = model.calculate_loss(token[:,:2], token_type[:,:2], pos[:,:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1fc2a0c47d0>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import einops\n",
    "\n",
    "\n",
    "pe = one_hot_pe # (len, dim)\n",
    "pos = torch.tensor([ # (batch_size, len)\n",
    "    [0,1,2,3,4],\n",
    "    [0,1,1,1,2]\n",
    "])\n",
    "pe_extracted = pe[pos]\n",
    "plt.imshow(pe_extracted[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([128, 32]), torch.Size([2, 5]))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pe.shape, pos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "pr = ds[0]\n",
    "\n",
    "def tokenize(pr: Pianoroll, length: int|None=None):\n",
    "    '''\n",
    "    token type:\n",
    "        -1: pad\n",
    "        0: frame\n",
    "        1: note\n",
    "    '''\n",
    "    current_frame = -1\n",
    "    tokens = []\n",
    "    token_types = []\n",
    "    pos = []\n",
    "    for note in pr.notes:\n",
    "        if note.onset > current_frame:\n",
    "            for _ in range(note.onset - current_frame):\n",
    "                tokens.append([0,0])\n",
    "                token_types.append(0)\n",
    "                pos.append(current_frame)\n",
    "            current_frame = note.onset\n",
    "        tokens.append([note.pitch, note.velocity])\n",
    "        token_types.append(1)\n",
    "        pos.append(note.onset)\n",
    "        \n",
    "\n",
    "    if length is not None and length > len(tokens):\n",
    "        for _ in range(length - len(tokens)):\n",
    "            tokens.append([0,0])\n",
    "            token_types.append(-1)\n",
    "            pos.append(current_frame)\n",
    "    tokens = torch.tensor(tokens[:length])\n",
    "    token_types = torch.tensor(token_types[:length])\n",
    "    pos = torch.tensor(pos[:length])\n",
    "\n",
    "    return tokens, token_types, pos\n",
    "\n",
    "\n",
    "def pad_to_length(x: Tensor, target_length: int, dim: int, pad_value: float):\n",
    "    padding_shape = list(x.shape)\n",
    "    padding_shape[dim] = target_length - x.shape[dim]\n",
    "    return torch.cat([x, torch.full(padding_shape, pad_value)])\n",
    "\n",
    "def pad_and_stack(batch: list[Tensor], pad_dim: int, pad_value: float=0, stack_dim: int=0, target_length: int|None=None) -> Tensor:\n",
    "    if target_length is None:\n",
    "        target_length = max(x.shape[pad_dim] for x in batch)\n",
    "    return torch.stack([pad_to_length(x, target_length, pad_dim, pad_value) for x in batch], stack_dim)\n",
    "\n",
    "def collate_fn(batch: list[Pianoroll]):\n",
    "    tokens_batch = []\n",
    "    token_types_batch = []\n",
    "    pos_batch = []\n",
    "    for pr in batch:\n",
    "        tokens, token_types, pos = tokenize(pr)\n",
    "        tokens_batch.append(tokens)\n",
    "        token_types_batch.append(token_types)\n",
    "        pos_batch.append(pos)\n",
    "    tokens_batch = pad_and_stack(tokens_batch, 0)\n",
    "    token_types_batch = pad_and_stack(token_types_batch, 0)\n",
    "    pos_batch = pad_and_stack(pos_batch, 0)\n",
    "    \n",
    "    return tokens_batch, token_types_batch\n",
    "\n",
    "dataloader = DataLoader(ds, batch_size=10, collate_fn=collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 268, 2])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(dataloader))[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
